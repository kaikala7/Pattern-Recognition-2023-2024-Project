{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E28Hg2l7iN8U",
        "outputId": "f56db5cb-9062-427f-fc5b-1d4df8605550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastfeedforward\n",
            "  Downloading fastfeedforward-0.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from fastfeedforward) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fastfeedforward) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fastfeedforward) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fastfeedforward) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fastfeedforward) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fastfeedforward) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fastfeedforward) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fastfeedforward) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->fastfeedforward) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->fastfeedforward) (1.3.0)\n",
            "Installing collected packages: fastfeedforward\n",
            "Successfully installed fastfeedforward-0.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install fastfeedforward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4sCRa1RVHzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c450c3c0-c70c-4ee4-d3d2-5453c62b723f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_call_impl', '_compiled_call_impl', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_load_from_state_dict', '_maybe_warn_non_full_backward_hook', '_named_members', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_version', '_wrapped_call_impl', 'add_module', 'apply', 'bfloat16', 'buffers', 'call_super_init', 'children', 'compile', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'eval_forward', 'extra_repr', 'float', 'forward', 'get_buffer', 'get_extra_state', 'get_leaf_param_group', 'get_node_param_group', 'get_parameter', 'get_submodule', 'half', 'ipu', 'load_state_dict', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'parameters', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_module', 'register_parameter', 'register_state_dict_pre_hook', 'requires_grad_', 'set_extra_state', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training_forward', 'type', 'xpu', 'zero_grad']\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"../fastfeedforward\")\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from fastfeedforward import FFF\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(dir(FFF))\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7h0VWSUVHzK",
        "outputId": "1bb38e62-6bc0-4123-bb70-e27be43ca705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 5\n",
        "activation = nn.ReLU()\n",
        "batch_size = 256\n",
        "\n",
        "leaf_width = 2          # [1, 2, 4, 8]\n",
        "training_width = 32     # [16, 32, 64, 128]    # number of all neurons in leafs\n",
        "\n",
        "depth = int(math.log2(training_width/leaf_width))\n",
        "print(depth)\n",
        "\"\"\"\n",
        "depth = []\n",
        "for w in leaf_width:\n",
        "    for ℓ in training_width:\n",
        "        d = math.log2(w / ℓ)\n",
        "        depth.append(d)\n",
        "\"\"\"\n",
        "entropy_effect = 3.0\n",
        "\n",
        "leaf_dropout = 0.0\n",
        "region_leak = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRYSGXq2VHzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a4076c2-f5f9-4285-eae8-2ec162ed9fe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 109775782.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 29755758.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 30782442.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 12691891.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/usps.bz2 to data_usps/usps.bz2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6579383/6579383 [00:01<00:00, 5012918.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/usps.t.bz2 to data_usps/usps.t.bz2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1831726/1831726 [00:01<00:00, 1653296.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data_fashion_mnist/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:05<00:00, 4474374.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data_fashion_mnist/FashionMNIST/raw/train-images-idx3-ubyte.gz to data_fashion_mnist/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data_fashion_mnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 268985.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data_fashion_mnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data_fashion_mnist/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data_fashion_mnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 4954597.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data_fashion_mnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data_fashion_mnist/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data_fashion_mnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 12324359.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data_fashion_mnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data_fashion_mnist/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Load the datasets\n",
        "from torchvision import datasets, transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# MNIST dataset\n",
        "dataset_mnist = datasets.MNIST('data', download=True, train=True, transform=transform)\n",
        "dataloader_mnist = torch.utils.data.DataLoader(dataset_mnist, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# MNIST testing dataset\n",
        "dataset_mnist_test = datasets.MNIST('data', download=True, train=False, transform=transform)\n",
        "dataloader_mnist_test = torch.utils.data.DataLoader(dataset_mnist, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# USPS dataset\n",
        "dataset_usps = datasets.USPS('data_usps', download=True, train=True, transform=transform)\n",
        "dataloader_usps = torch.utils.data.DataLoader(dataset_usps, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# USPS testing dataset\n",
        "dataset_usps_test = datasets.USPS('data_usps', download=True, train=False, transform=transform)\n",
        "dataloader_usps_test = torch.utils.data.DataLoader(dataset_usps_test, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# FashionMNIST dataset\n",
        "dataset_fashion_mnist = datasets.FashionMNIST('data_fashion_mnist', download=True, train=True, transform=transform)\n",
        "dataloader_fashion_mnist = torch.utils.data.DataLoader(dataset_fashion_mnist, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# FashionMNIST testing dataset\n",
        "dataset_fashion_mnist_test = datasets.FashionMNIST('data_fashion_mnist', download=True, train=False, transform=transform)\n",
        "dataloader_fashion_mnist_test = torch.utils.data.DataLoader(dataset_fashion_mnist_test, batch_size=batch_size, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjIDitXOwxAm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eP5pHOIEwwdy"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import List, Optional\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "class LocalAdam(torch.optim.Optimizer):\n",
        "    \"\"\"Implements Adam algorithm with local batch size support.\n",
        "\n",
        "    All input parameters are as per :class:`torch.optim.Adam` except for the following:\n",
        "     - `usage`: a tensor of shape (N,) where N is the number of parameter blocks (to have separate gradient accumulations) in the group. If specified, the optimizer will only update parameters where usage[i] >= local_batch_size[i].\n",
        "     - `local_batch_size`: a tensor of shape (N,) where N is the number of parameter blocks (to have separate gradient accumulations) in the group. If specified, the optimizer will only update parameters where usage[i] >= local_batch_size[i].\n",
        "     - `differentiable`, `fusion`, and `foreach` from the original implementation are not supported.\n",
        "    \"\"\"\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n",
        "                 weight_decay=0, amsgrad=False, *,\n",
        "                 usage: Optional[torch.Tensor] = None, local_batch_size: Optional[int] = None,\n",
        "                 maximize: bool = False):\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
        "        if not 0.0 <= weight_decay:\n",
        "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
        "        if usage is not None and not isinstance(usage, torch.Tensor):\n",
        "            raise ValueError(\"Parameter usage must be a tensor\")\n",
        "        if local_batch_size is not None and local_batch_size.any() <= 0:\n",
        "            raise ValueError(\"Invalid local_batch_size value: {}, must be > 0 or unspecified altogether (None)\".format(local_batch_size))\n",
        "\n",
        "        params = list(params)\n",
        "\n",
        "        for param in params:\n",
        "            if not isinstance(param, dict):\n",
        "                continue\n",
        "\n",
        "            if 'usage' in param:\n",
        "                if not isinstance(param['usage'], torch.Tensor):\n",
        "                    raise ValueError(\"Parameter usage must be a tensor\")\n",
        "                for p in param['params']:\n",
        "                    if p.size(0) != param['usage'].size(0):\n",
        "                        raise ValueError(\"Every tensor in param['params'] must have the same size(0) as param['usage'].size(0)\")\n",
        "\n",
        "            if 'local_batch_size' in param:\n",
        "                if not isinstance(param['local_batch_size'], int):\n",
        "                    raise ValueError(\"Parameter local_batch_size must be an int\")\n",
        "                if param['local_batch_size'] <= 0:\n",
        "                    raise ValueError(\"Parameter local_batch_size must be >0\")\n",
        "\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
        "                        weight_decay=weight_decay, amsgrad=amsgrad,\n",
        "                        maximize=maximize,\n",
        "                        usage=usage, local_batch_size=local_batch_size,)\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super().__setstate__(state)\n",
        "        for group in self.param_groups:\n",
        "            group.setdefault('amsgrad', False)\n",
        "            group.setdefault('maximize', False)\n",
        "            group.setdefault('usage', None)\n",
        "            group.setdefault('local_batch_size', None)\n",
        "\n",
        "        state_values = list(self.state.values())\n",
        "        step_is_tensor = (len(state_values) != 0) and torch.is_tensor(state_values[0]['step'])\n",
        "        if not step_is_tensor:\n",
        "            for s in state_values:\n",
        "                s['step'] = torch.tensor(s['step'], dtype=torch.float32)\n",
        "\n",
        "    def _init_group(\n",
        "        self,\n",
        "        group,\n",
        "        params_with_grad,\n",
        "        grads,\n",
        "        u_list,\n",
        "        lbs_list,\n",
        "        exp_avgs,\n",
        "        exp_avg_sqs,\n",
        "        max_exp_avg_sqs,\n",
        "        state_steps\n",
        "    ):\n",
        "        for p in group['params']:\n",
        "            if p.grad is not None:\n",
        "                params_with_grad.append(p)\n",
        "                if p.grad.is_sparse:\n",
        "                    raise RuntimeError('LocalAdam does not support sparse gradients; perhaps consider torch.optim.SparseAdam')\n",
        "                grads.append(p.grad)\n",
        "\n",
        "                if group['usage'] is not None and group['local_batch_size'] is not None:\n",
        "                    u_list.append(group['usage'])\n",
        "                    lbs_list.append(group['local_batch_size'])\n",
        "                else:\n",
        "                    u_list.append(None)\n",
        "                    lbs_list.append(None)\n",
        "\n",
        "                state = self.state[p]\n",
        "                # Lazy state initialization\n",
        "                if len(state) == 0:\n",
        "                    descent_controlled_by_usage = group['usage'] is not None and group['local_batch_size'] is not None\n",
        "                    state['step'] = (\n",
        "                        torch.tensor(0.) if not descent_controlled_by_usage else torch.zeros_like(group['usage'], dtype=torch.float32, memory_format=torch.preserve_format)\n",
        "                    )\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
        "                    if group['amsgrad']:\n",
        "                        # Maintains max of all exp. moving avg. of sq. grad. values\n",
        "                        state['max_exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
        "\n",
        "                exp_avgs.append(state['exp_avg'])\n",
        "                exp_avg_sqs.append(state['exp_avg_sq'])\n",
        "\n",
        "                if group['amsgrad']:\n",
        "                    max_exp_avg_sqs.append(state['max_exp_avg_sq'])\n",
        "                state_steps.append(state['step'])\n",
        "\n",
        "    def zero_grad(self, set_to_none: bool = False):\n",
        "        usage_zeroing_per_usage_holder = {}\n",
        "        for group in self.param_groups:\n",
        "            u = group['usage']\n",
        "            if u is not None and group['local_batch_size'] is not None:\n",
        "                where_to_zero = u >= group['local_batch_size']\n",
        "            else:\n",
        "                where_to_zero = None\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is not None:\n",
        "                    if where_to_zero is None:\n",
        "                        if set_to_none:\n",
        "                            p.grad = None\n",
        "                        else:\n",
        "                            if p.grad.grad_fn is not None:\n",
        "                                p.grad.detach_()\n",
        "                            # DO NOT MODIFY requires_grad even though the base implementation does; ever!\n",
        "                            p.grad.zero_()\n",
        "                    else:\n",
        "                        p.grad[where_to_zero] = 0\n",
        "\n",
        "            if where_to_zero is not None:\n",
        "                if u in usage_zeroing_per_usage_holder:\n",
        "                    usage_zeroing_per_usage_holder[u].logical_or_(where_to_zero)\n",
        "                else:\n",
        "                    usage_zeroing_per_usage_holder[u] = where_to_zero.clone().detach()\n",
        "\n",
        "        # now we can zero out the gradients for each usage holder\n",
        "        for u, where_to_zero in usage_zeroing_per_usage_holder.items():\n",
        "            u[where_to_zero] = 0\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "\n",
        "        Args:\n",
        "            closure (Callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            with torch.enable_grad():\n",
        "                loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            params_with_grad = []\n",
        "            grads = []\n",
        "            u_list = []\n",
        "            lbs_list = []\n",
        "            exp_avgs = []\n",
        "            exp_avg_sqs = []\n",
        "            max_exp_avg_sqs = []\n",
        "            state_steps = []\n",
        "            beta1, beta2 = group['betas']\n",
        "\n",
        "            self._init_group(\n",
        "                group,\n",
        "                params_with_grad,\n",
        "                grads,\n",
        "                u_list,\n",
        "                lbs_list,\n",
        "                exp_avgs,\n",
        "                exp_avg_sqs,\n",
        "                max_exp_avg_sqs,\n",
        "                state_steps)\n",
        "\n",
        "            adam(\n",
        "                params_with_grad,\n",
        "                grads,\n",
        "                u_list,\n",
        "                lbs_list,\n",
        "                exp_avgs,\n",
        "                exp_avg_sqs,\n",
        "                max_exp_avg_sqs,\n",
        "                state_steps,\n",
        "                amsgrad=group['amsgrad'],\n",
        "                beta1=beta1,\n",
        "                beta2=beta2,\n",
        "                lr=group['lr'],\n",
        "                weight_decay=group['weight_decay'],\n",
        "                eps=group['eps'],\n",
        "                maximize=group['maximize'],\n",
        "                grad_scale=getattr(self, \"grad_scale\", None),\n",
        "                found_inf=getattr(self, \"found_inf\", None),\n",
        "            )\n",
        "\n",
        "        return loss\n",
        "\n",
        "def adam(params: List[Tensor],\n",
        "         grads: List[Tensor],\n",
        "         u_list: List[Optional[Tensor]],\n",
        "         lbs_list: List[Optional[Tensor]],\n",
        "         exp_avgs: List[Tensor],\n",
        "         exp_avg_sqs: List[Tensor],\n",
        "         max_exp_avg_sqs: List[Tensor],\n",
        "         state_steps: List[Tensor],\n",
        "         # kwonly args with defaults are not supported by functions compiled with torchscript issue #70627\n",
        "         # setting this as kwarg for now as functional API is compiled by torch/distributed/optim\n",
        "         grad_scale: Optional[Tensor] = None,\n",
        "         found_inf: Optional[Tensor] = None,\n",
        "         *,\n",
        "         amsgrad: bool,\n",
        "         beta1: float,\n",
        "         beta2: float,\n",
        "         lr: float,\n",
        "         weight_decay: float,\n",
        "         eps: float,\n",
        "         maximize: bool):\n",
        "    r\"\"\"Functional API that performs Adam algorithm computation.\n",
        "    See :class:`~torch.optim.Adam` for details.\n",
        "    \"\"\"\n",
        "\n",
        "    if not all(isinstance(t, torch.Tensor) for t in state_steps):\n",
        "        raise RuntimeError(\"API has changed, `state_steps` argument must contain a list of singleton tensors\")\n",
        "\n",
        "    func = _single_tensor_adam\n",
        "\n",
        "    func(params,\n",
        "         grads,\n",
        "         u_list,\n",
        "         lbs_list,\n",
        "         exp_avgs,\n",
        "         exp_avg_sqs,\n",
        "         max_exp_avg_sqs,\n",
        "         state_steps,\n",
        "         amsgrad=amsgrad,\n",
        "         beta1=beta1,\n",
        "         beta2=beta2,\n",
        "         lr=lr,\n",
        "         weight_decay=weight_decay,\n",
        "         eps=eps,\n",
        "         maximize=maximize,\n",
        "         grad_scale=grad_scale,\n",
        "         found_inf=found_inf)\n",
        "\n",
        "@torch.no_grad()\n",
        "def _single_tensor_adam(params: List[Tensor],\n",
        "                        grads: List[Tensor],\n",
        "                        u_list: List[Optional[Tensor]],\n",
        "                        lbs_list: List[Optional[Tensor]],\n",
        "                        exp_avgs: List[Tensor],\n",
        "                        exp_avg_sqs: List[Tensor],\n",
        "                        max_exp_avg_sqs: List[Tensor],\n",
        "                        state_steps: List[Tensor],\n",
        "                        grad_scale: Optional[Tensor],\n",
        "                        found_inf: Optional[Tensor],\n",
        "                        *,\n",
        "                        amsgrad: bool,\n",
        "                        beta1: float,\n",
        "                        beta2: float,\n",
        "                        lr: float,\n",
        "                        weight_decay: float,\n",
        "                        eps: float,\n",
        "                        maximize: bool\n",
        "                        ):\n",
        "\n",
        "    assert grad_scale is None and found_inf is None\n",
        "\n",
        "    for i, param in enumerate(params):\n",
        "        grad = grads[i] if not maximize else -grads[i]\n",
        "        exp_avg = exp_avgs[i]\n",
        "        exp_avg_sq = exp_avg_sqs[i]\n",
        "        u = u_list[i]\n",
        "        lbs = lbs_list[i]\n",
        "\n",
        "        # find out where updates are due\n",
        "        if u is not None and lbs is not None:\n",
        "            to_update = u >= lbs\n",
        "            to_update_expanded = to_update.reshape(to_update.shape + (1,) * (len(grad.shape) - len(to_update.shape)))\n",
        "            to_update_expanded = to_update_expanded.expand_as(grad)\n",
        "        else:\n",
        "            to_update = None\n",
        "\n",
        "        # correct the grad where more accumulations have happened\n",
        "        if to_update is not None:\n",
        "            correction = torch.where(to_update, u / lbs, torch.ones_like(u))\n",
        "            correction_expanded = correction.reshape(correction.shape + (1,) * (len(grad.shape) - len(correction.shape)))\n",
        "            correction_expanded = correction_expanded.expand_as(grad)\n",
        "            grad = grad / correction_expanded\n",
        "\n",
        "        # update the step counter where an update is imminent\n",
        "        if to_update is not None:\n",
        "            state_steps[i].copy_(torch.where(to_update, state_steps[i] + 1, state_steps[i]))\n",
        "        else:\n",
        "            state_steps[i].add_(1)\n",
        "\n",
        "        if weight_decay != 0:\n",
        "            grad = grad.add(param, alpha=weight_decay)\n",
        "\n",
        "        if torch.is_complex(param):\n",
        "            grad = torch.view_as_real(grad)\n",
        "            exp_avg = torch.view_as_real(exp_avg)\n",
        "            exp_avg_sq = torch.view_as_real(exp_avg_sq)\n",
        "            param = torch.view_as_real(param)\n",
        "\n",
        "        # Decay the first and second moment running average coefficient\n",
        "        if to_update is not None:\n",
        "            exp_avg.copy_(torch.where(to_update_expanded, exp_avg.mul_(beta1).add(grad, alpha=1 - beta1), exp_avg))\n",
        "            exp_avg_sq.copy_(torch.where(to_update_expanded, exp_avg_sq.mul(beta2).addcmul(grad, grad.conj(), value=1 - beta2), exp_avg_sq))\n",
        "        else:\n",
        "            exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
        "            exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=1 - beta2)\n",
        "\n",
        "        step = state_steps[i]\n",
        "\n",
        "        bias_correction1 = torch.where(to_update, 1 - beta1 ** step, torch.ones_like(step))\n",
        "        bias_correction2 = torch.where(to_update, 1 - beta2 ** step, torch.ones_like(step))\n",
        "        bias_correction2 = bias_correction2.reshape(bias_correction2.shape + (1,) * (len(exp_avg_sq.shape) - len(bias_correction2.shape)))\n",
        "\n",
        "        step_size = lr / bias_correction1\n",
        "        step_size = step_size.reshape(step_size.shape + (1,) * (len(exp_avg.shape) - len(step_size.shape)))\n",
        "\n",
        "        bias_correction2_sqrt = torch.sqrt(bias_correction2)\n",
        "\n",
        "        if amsgrad:\n",
        "            # Maintains the maximum of all 2nd moment running avg. till now\n",
        "            if to_update is not None:\n",
        "                torch.maximum(\n",
        "                    max_exp_avg_sqs[i],\n",
        "                    torch.where(to_update_expanded, exp_avg_sq, max_exp_avg_sqs[i]),\n",
        "                    out=max_exp_avg_sqs[i]\n",
        "                )\n",
        "            else:\n",
        "                torch.maximum(max_exp_avg_sqs[i], exp_avg_sq, out=max_exp_avg_sqs[i])\n",
        "\n",
        "            # Use the max. for normalizing running avg. of gradient\n",
        "            denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n",
        "        else:\n",
        "            denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)\n",
        "\n",
        "        if to_update is None:\n",
        "            param.copy_(param + exp_avg / denom * -step_size)\n",
        "        else:\n",
        "            param.copy_(torch.where(\n",
        "                to_update_expanded,\n",
        "                param + exp_avg / denom * -step_size,\n",
        "                param\n",
        "            ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2ow1-w_VHzN"
      },
      "outputs": [],
      "source": [
        "# setup the FFF model\n",
        "model = FFF(input_width=784, leaf_width=leaf_width, output_width=10, depth=depth, activation=activation, dropout=leaf_dropout, region_leak=region_leak)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZtvc40uVHzP"
      },
      "outputs": [],
      "source": [
        "# train the model\n",
        "training_losses = []\n",
        "training_accuracies = []\n",
        "training_entropies = []\n",
        "epoch_testing_losses = []\n",
        "epoch_testing_accuracies = []\n",
        "\n",
        "print(model.parameters())\n",
        "\n",
        "parameters = list(model.parameters())\n",
        "\n",
        "for param_group in parameters:\n",
        "    print(param_group)\n",
        "\n",
        "\n",
        "\n",
        "num_blocks = 16 #len(parameters)\n",
        "usage = torch.tensor([0] * num_blocks)\n",
        "print(usage)\n",
        "local_batch_size = torch.tensor([32] * num_blocks)\n",
        "print(local_batch_size)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "for epoch in range(n_epochs):\n",
        "\tprint(\"Epoch\", epoch)\n",
        "\n",
        "\tmodel.train()\n",
        "\tfor batch_images, batch_labels in tqdm(dataloader_mnist):\n",
        "\t\toptimizer.zero_grad()\n",
        "\n",
        "\t\toutput, node_entropies = model(batch_images.view(-1, 784), return_entropies=True)\n",
        "\t\tnode_entropy_mean = node_entropies.mean()\n",
        "\t\tloss = criterion(output, batch_labels) + entropy_effect * node_entropy_mean\n",
        "\t\taccuracy = (output.argmax(dim=1) == batch_labels).detach().float().mean()\n",
        "\n",
        "\t\ttraining_losses.append(loss.item())\n",
        "\t\ttraining_accuracies.append(accuracy.item())\n",
        "\t\ttraining_entropies.append(node_entropy_mean.item())\n",
        "\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\n",
        "\t# test the model\n",
        "\tmodel.eval()\n",
        "\ttesting_losses = []\n",
        "\ttesting_accuracies = []\n",
        "\tfor batch_images, batch_labels in tqdm(dataloader_mnist_test):\n",
        "\t\toutput = model(batch_images.view(-1, 784))\n",
        "\t\tloss = criterion(output, batch_labels)\n",
        "\t\taccuracy = (output.argmax(dim=1) == batch_labels).detach().float().mean()\n",
        "\n",
        "\t\ttesting_losses.append(loss.item())\n",
        "\t\ttesting_accuracies.append(accuracy.item())\n",
        "\tepoch_testing_losses.append(sum(testing_losses) / len(testing_losses))\n",
        "\tepoch_testing_accuracies.append(sum(testing_accuracies) / len(testing_accuracies))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_95ggeNiHtdw"
      },
      "outputs": [],
      "source": [
        "def train1(model, dataloader_training, dataloader_testing, n_epochs=10, entropy_effect=3.0, learning_rate=0.02, patience=3):\n",
        "\n",
        "    # Initialize optimizer and loss function\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_training_loss = float('inf')\n",
        "    consecutive_no_improvement = 0\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Epoch\", epoch)\n",
        "        training_losses = []\n",
        "        training_accuracies = []\n",
        "\n",
        "        # Training\n",
        "        model.train()\n",
        "        for batch_images, batch_labels in tqdm(dataloader_training):\n",
        "\n",
        "            batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output, node_entropies = model(batch_images.view(-1, 784), return_entropies=True)\n",
        "            node_entropy_mean = node_entropies.mean()\n",
        "            loss = criterion(output, batch_labels) + entropy_effect * node_entropy_mean\n",
        "            accuracy = (output.argmax(dim=1) == batch_labels).detach().float().mean()\n",
        "\n",
        "            training_losses.append(loss.item())\n",
        "            training_accuracies.append(accuracy.item())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Calculate training metrics\n",
        "        training_loss = sum(training_losses)\n",
        "        print(f\"Epoch {epoch} - Training Loss: {training_loss}\")\n",
        "\n",
        "        training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "        print(f\"Epoch {epoch} - Training Accuracy: {training_accuracy}\")\n",
        "\n",
        "        \"\"\"\n",
        "        # Testing\n",
        "        model.eval()\n",
        "        testing_losses = []\n",
        "        testing_accuracies = []\n",
        "        for batch_images, batch_labels in tqdm(dataloader_testing):\n",
        "\n",
        "            batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
        "\n",
        "            output = model(batch_images.view(-1, 784))\n",
        "            loss = criterion(output, batch_labels)\n",
        "            accuracy = (output.argmax(dim=1) == batch_labels).detach().float().mean()\n",
        "\n",
        "            testing_losses.append(loss.item())\n",
        "            testing_accuracies.append(accuracy.item())\n",
        "\n",
        "        # Calculate testing metrics\n",
        "        testing_loss = sum(testing_losses) / len(testing_losses)\n",
        "        print(f\"Epoch {epoch} - Testing Loss: {testing_loss}\")\n",
        "\n",
        "        testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "        print(f\"Epoch {epoch} - Testing Accuracy: {testing_accuracy}\")\n",
        "        \"\"\"\n",
        "        # Early Stopping\n",
        "        if training_loss < best_training_loss:\n",
        "            best_training_loss = training_loss\n",
        "            consecutive_no_improvement = 0\n",
        "        else:\n",
        "            consecutive_no_improvement += 1\n",
        "\n",
        "        if consecutive_no_improvement >= patience:\n",
        "            print(f\"Early stopping.\")\n",
        "            break\n",
        "\n",
        "    return model\n",
        "\n",
        "def eval1(model, dataloader_testing):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    model.eval()\n",
        "    # testing_losses = []\n",
        "    testing_accuracies = []\n",
        "    for batch_images, batch_labels in tqdm(dataloader_testing):\n",
        "        batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
        "        output = model(batch_images.view(-1, 784))\n",
        "        # loss = criterion(output, batch_labels)\n",
        "        accuracy = (output.argmax(dim=1) == batch_labels).detach().float().mean()\n",
        "        # testing_losses.append(loss.item())\n",
        "        testing_accuracies.append(accuracy.item())\n",
        "\n",
        "    # Calculate testing metrics\n",
        "    # testing_loss = sum(testing_losses) / len(testing_losses)\n",
        "    testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "\n",
        "    return testing_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "3ARs4acGMUe2",
        "outputId": "9e7c0fb7-1e9e-440f-dbc7-3eeaa64b29da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 235/235 [00:16<00:00, 14.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - Training Loss: 525.8235847949982\n",
            "Epoch 0 - Training Accuracy: 0.18043550531914893\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 196/235 [00:14<00:02, 13.60it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-f8b79098a34d>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFFF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaf_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleaf_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleaf_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion_leak\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregion_leak\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrained_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_effect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mentropy_effect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataloader_mnist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-73ce3f0e780e>\u001b[0m in \u001b[0;36mtrain1\u001b[0;34m(model, dataloader_training, dataloader_testing, n_epochs, entropy_effect, learning_rate, patience)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;31m# handle PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I;16\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "model = FFF(input_width=784, leaf_width=leaf_width, output_width=10, depth=depth, activation=activation, dropout=leaf_dropout, region_leak=region_leak)\n",
        "model.to(device)\n",
        "trained_metrics = train1(model, dataloader_mnist, dataloader_mnist, n_epochs=500, entropy_effect=entropy_effect, learning_rate=0.001, patience=500)\n",
        "print(\"\\n\")\n",
        "print(eval1(model,dataloader_mnist))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rq9PTriEGJO1"
      },
      "outputs": [],
      "source": [
        "def train2(model, dataloader_training, dataloader_testing, n_epochs=10, entropy_effect=3.0, learning_rate=0.02, patience=3):\n",
        "\n",
        "    # Initialize optimizer and loss function\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_testing_loss = float('inf')\n",
        "    consecutive_no_improvement = 0\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Epoch\", epoch)\n",
        "        training_losses = []\n",
        "        training_accuracies = []\n",
        "\n",
        "        # Training\n",
        "        model.train()\n",
        "        for batch_images, batch_labels in tqdm(dataloader_training):\n",
        "\n",
        "            batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output, node_entropies = model(batch_images.view(-1, 784), return_entropies=True)\n",
        "            node_entropy_mean = node_entropies.mean()\n",
        "            loss = criterion(output, batch_labels) + entropy_effect * node_entropy_mean\n",
        "            accuracy = (output.argmax(dim=1) == batch_labels).detach().float().mean()\n",
        "\n",
        "            training_losses.append(loss.item())\n",
        "            training_accuracies.append(accuracy.item())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Calculate training metrics\n",
        "        training_loss = sum(training_losses)\n",
        "        print(f\"Epoch {epoch} - Training Loss: {training_loss}\")\n",
        "\n",
        "        training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "        print(f\"Epoch {epoch} - Training Accuracy: {training_accuracy}\")\n",
        "\n",
        "        # Testing\n",
        "        model.eval()\n",
        "        # print(model.training)\n",
        "        testing_losses = []\n",
        "        testing_accuracies = []\n",
        "        for batch_images, batch_labels in tqdm(dataloader_testing):\n",
        "\n",
        "            batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
        "\n",
        "            output = model(batch_images.view(-1, 784))\n",
        "            loss = criterion(output, batch_labels)\n",
        "            accuracy = (output.argmax(dim=1) == batch_labels).detach().float().mean()\n",
        "\n",
        "            testing_losses.append(loss.item())\n",
        "            testing_accuracies.append(accuracy.item())\n",
        "\n",
        "        # Calculate testing metrics\n",
        "        testing_loss = sum(testing_losses)\n",
        "        print(f\"Epoch {epoch} - Testing Loss: {testing_loss}\")\n",
        "\n",
        "        testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "        print(f\"Epoch {epoch} - Testing Accuracy: {testing_accuracy}\")\n",
        "\n",
        "        # Early Stopping\n",
        "        if testing_loss < best_testing_loss:\n",
        "            best_testing_loss = testing_loss\n",
        "            consecutive_no_improvement = 0\n",
        "        else:\n",
        "            consecutive_no_improvement += 1\n",
        "\n",
        "        if consecutive_no_improvement >= patience:\n",
        "            print(f\"Early stopping.\")\n",
        "            break\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "ESN4b29VKh85",
        "outputId": "5f82d0af-0dd2-4ee2-af93-25a7598284b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 235/235 [00:19<00:00, 11.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - Training Loss: 220.86019563674927\n",
            "Epoch 0 - Training Accuracy: 0.7505762412192973\n",
            "False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 235/235 [00:26<00:00,  8.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - Testing Loss: 109.03976666927338\n",
            "Epoch 0 - Testing Accuracy: 0.8688940603682336\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 235/235 [00:20<00:00, 11.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Training Loss: 92.03901898860931\n",
            "Epoch 1 - Training Accuracy: 0.8894337321849579\n",
            "False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 179/235 [00:20<00:06,  8.94it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-3b73ee317911>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFFF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaf_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleaf_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion_leak\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregion_leak\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrained_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_mnist_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_effect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataloader_mnist_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-6137c3b0feb0>\u001b[0m in \u001b[0;36mtrain2\u001b[0;34m(model, dataloader_training, dataloader_testing, n_epochs, entropy_effect, learning_rate, patience)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fastfeedforward/fff.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, return_entropies, use_hard_decisions)\u001b[0m\n\u001b[1;32m    335\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0muse_hard_decisions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_hard_decisions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot use soft decisions during evaluation.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m                         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0meval_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fastfeedforward/fff.py\u001b[0m in \u001b[0;36meval_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    377\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                         \u001b[0mleaf_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleaves\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m \t\t\tlogits = torch.matmul(\n\u001b[0m\u001b[1;32m    380\u001b[0m                                 \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                      \u001b[0;31m# (1, self.input_width)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw1s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleaf_index\u001b[0m\u001b[0;34m]\u001b[0m                            \u001b[0;31m# (self.input_width, self.leaf_width)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "model = FFF(input_width=784, leaf_width=16, output_width=10, depth=3, activation=activation, dropout=leaf_dropout, region_leak=region_leak)\n",
        "model.to(device)\n",
        "trained_metrics = train2(model, dataloader_mnist, dataloader_mnist_test, n_epochs=500, entropy_effect=3.0, learning_rate=0.001, patience=500)\n",
        "print(\"\\n\")\n",
        "print(eval1(model,dataloader_mnist_test))\n",
        "# max acc 0.58 for lr 0.001 batch size 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DR9rK66jNxiB"
      },
      "outputs": [],
      "source": [
        "# simple ff\n",
        "\n",
        "class SimpleFeedForward(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleFeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def train_simple_ff(model, dataloader_training, dataloader_testing, n_epochs=10, learning_rate=0.02, patience=3):\n",
        "\n",
        "    # Initialize optimizer and loss function\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_testing_loss = float('inf')\n",
        "    consecutive_no_improvement = 0\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Epoch\", epoch)\n",
        "        training_losses = []\n",
        "        training_accuracies = []\n",
        "\n",
        "        # Training\n",
        "        model.train()\n",
        "        for batch_images, batch_labels in tqdm(dataloader_training):\n",
        "\n",
        "            batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(batch_images.view(-1, 784))\n",
        "            loss = criterion(output, batch_labels)\n",
        "            accuracy = (output.argmax(dim=1) == batch_labels).detach().float().mean()\n",
        "\n",
        "            training_losses.append(loss.item())\n",
        "            training_accuracies.append(accuracy.item())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Calculate training metrics\n",
        "        training_loss = sum(training_losses)\n",
        "        print(f\"Epoch {epoch} - Training Loss: {training_loss}\")\n",
        "\n",
        "        training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "        print(f\"Epoch {epoch} - Training Accuracy: {training_accuracy}\")\n",
        "\n",
        "        # Testing\n",
        "        model.eval()\n",
        "        testing_losses = []\n",
        "        testing_accuracies = []\n",
        "        for batch_images, batch_labels in tqdm(dataloader_testing):\n",
        "\n",
        "            batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
        "\n",
        "            output = model(batch_images.view(-1, 784))\n",
        "            loss = criterion(output, batch_labels)\n",
        "            accuracy = (output.argmax(dim=1) == batch_labels).detach().float().mean()\n",
        "\n",
        "            testing_losses.append(loss.item())\n",
        "            testing_accuracies.append(accuracy.item())\n",
        "\n",
        "        # Calculate testing metrics\n",
        "        testing_loss = sum(testing_losses)\n",
        "        print(f\"Epoch {epoch} - Testing Loss: {testing_loss}\")\n",
        "\n",
        "        testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "        print(f\"Epoch {epoch} - Testing Accuracy: {testing_accuracy}\")\n",
        "\n",
        "        # Early Stopping\n",
        "        if testing_loss < best_testing_loss:\n",
        "            best_testing_loss = testing_loss\n",
        "            consecutive_no_improvement = 0\n",
        "        else:\n",
        "            consecutive_no_improvement += 1\n",
        "\n",
        "        if consecutive_no_improvement >= patience:\n",
        "            print(f\"Early stopping.\")\n",
        "            break\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "n59sJE7mPkiZ",
        "outputId": "50db23a2-2384-4d94-d682-f6d21c059729"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 235/235 [00:18<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - Training Loss: 127.96920724213123\n",
            "Epoch 0 - Training Accuracy: 0.850376773134191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 235/235 [00:18<00:00, 12.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - Testing Loss: 77.14136812090874\n",
            "Epoch 0 - Testing Accuracy: 0.9027648492062346\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 198/235 [00:15<00:02, 13.00it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-56cd10fd038b>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Call the training function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_simple_ff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_mnist_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Evaluate the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-3216d4ba897d>\u001b[0m in \u001b[0;36mtrain_simple_ff\u001b[0;34m(model, dataloader_training, dataloader_testing, n_epochs, learning_rate, patience)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;31m# handle PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I;16\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__array_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m                 \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mMemoryError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRecursionError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "input_size = 784\n",
        "hidden_size = 128\n",
        "output_size = 10\n",
        "\n",
        "# Create a SimpleFeedForward\n",
        "model = SimpleFeedForward(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n",
        "\n",
        "# Move the model to the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Call the training function\n",
        "trained_model = train_simple_ff(model, dataloader_mnist, dataloader_mnist_test, n_epochs=500, learning_rate=0.001, patience=500)\n",
        "\n",
        "# Evaluate the trained model\n",
        "print(\"\\n\")\n",
        "print(eval1(trained_model, dataloader_mnist_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PQ3MIiLVHzT",
        "outputId": "fb2528a8-8c5f-4c14-f47c-ca02d5813485"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to data_svhn/train_32x32.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 182040794/182040794 [00:21<00:00, 8588613.59it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data_cifar10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 100177563.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data_cifar10/cifar-10-python.tar.gz to data_cifar10\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data_cifar100/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 169001437/169001437 [00:01<00:00, 103380848.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data_cifar100/cifar-100-python.tar.gz to data_cifar100\n"
          ]
        }
      ],
      "source": [
        "# Second series of experiements\n",
        "# datasets SVHN, CIFAR10, CIFAR100\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Set your desired batch size\n",
        "batch_size = 64\n",
        "\n",
        "# Transformations\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# SVHN dataset\n",
        "dataset_svhn = datasets.SVHN('data_svhn', download=True, split='train', transform=transform)\n",
        "dataloader_svhn = torch.utils.data.DataLoader(dataset_svhn, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# CIFAR-10 dataset\n",
        "dataset_cifar10 = datasets.CIFAR10('data_cifar10', download=True, train=True, transform=transform)\n",
        "dataloader_cifar10 = torch.utils.data.DataLoader(dataset_cifar10, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# CIFAR-100 dataset\n",
        "dataset_cifar100 = datasets.CIFAR100('data_cifar100', download=True, train=True, transform=transform)\n",
        "dataloader_cifar100 = torch.utils.data.DataLoader(dataset_cifar100, batch_size=batch_size, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilruttJzu5po"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olDQhjUju5PD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops\n",
        "!pip install vit_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_dN4T64h8Fe",
        "outputId": "265ba47c-4a71-4e63-bc39-78b0a6dd04c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m683.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.7.0\n",
            "Collecting vit_pytorch\n",
            "  Downloading vit_pytorch-1.6.5-py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: einops>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from vit_pytorch) (0.7.0)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from vit_pytorch) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from vit_pytorch) (0.16.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->vit_pytorch) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->vit_pytorch) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->vit_pytorch) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->vit_pytorch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->vit_pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->vit_pytorch) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->vit_pytorch) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->vit_pytorch) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->vit_pytorch) (1.3.0)\n",
            "Installing collected packages: vit_pytorch\n",
            "Successfully installed vit_pytorch-1.6.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoK7ej0Cu45m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.cuda\n",
        "\n",
        "from einops import rearrange, repeat\n",
        "from einops.layers.torch import Rearrange\n",
        "\n",
        "# helpers\n",
        "\n",
        "def pair(t):\n",
        "    return t if isinstance(t, tuple) else (t, t)\n",
        "\n",
        "# classes\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head *  heads\n",
        "        project_out = not (heads == 1 and dim_head == dim)\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        self.attend = nn.Softmax(dim = -1)\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(inner_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        ) if project_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
        "\n",
        "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
        "\n",
        "        attn = self.attend(dots)\n",
        "\n",
        "        out = torch.matmul(attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        return self.to_out(out)\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0., fff_model=False):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)),\n",
        "                PreNorm(dim, FFF(input_width=dim, leaf_width=32, output_width=dim, depth=2, activation=nn.ReLU(), dropout=0.0, train_hardened=True, region_leak=0.0)) if fff_model\n",
        "                else PreNorm(dim, SimpleFeedForward(dim, mlp_dim, dim))\n",
        "            ]))\n",
        "    def forward(self, x):\n",
        "        total_time = 0\n",
        "        for attn, ff in self.layers:\n",
        "            x = attn(x) + x\n",
        "\n",
        "            #start_time = torch.cuda.Event(enable_timing=True)\n",
        "            #start_time.record()\n",
        "            y = ff(x)\n",
        "            #end_time = torch.cuda.Event(enable_timing=True)\n",
        "            #end_time.record()\n",
        "            #torch.cuda.synchronize()\n",
        "            #total_time += start_time.elapsed_time(end_time)\n",
        "\n",
        "            x = x + y\n",
        "\n",
        "        return x,total_time\n",
        "\n",
        "class myViT(nn.Module):\n",
        "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0., fff_model=False):\n",
        "        super().__init__()\n",
        "        image_height, image_width = pair(image_size)\n",
        "        patch_height, patch_width = pair(patch_size)\n",
        "\n",
        "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
        "\n",
        "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
        "        patch_dim = channels * patch_height * patch_width\n",
        "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
        "\n",
        "        self.to_patch_embedding = nn.Sequential(\n",
        "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n",
        "            nn.Linear(patch_dim, dim),\n",
        "        )\n",
        "\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "        self.dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout, fff_model=fff_model)\n",
        "\n",
        "        self.pool = pool\n",
        "        self.to_latent = nn.Identity()\n",
        "\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, num_classes)\n",
        "        )\n",
        "        self.total_time = 0\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = self.to_patch_embedding(img)\n",
        "        b, n, _ = x.shape\n",
        "\n",
        "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n",
        "\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "\n",
        "        x += self.pos_embedding[:, :(n + 1)]\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x, one_pass_time = self.transformer(x)\n",
        "\n",
        "        self.total_time += one_pass_time\n",
        "\n",
        "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
        "\n",
        "        x = self.to_latent(x)\n",
        "\n",
        "        return self.mlp_head(x), self.total_time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "activation = nn.ReLU()\n",
        "batch_size = 256\n",
        "\n",
        "leaf_width = 32         # [1, 2, 4, 8]\n",
        "training_width = 128     # [16, 32, 64, 128]    # number of all neurons in leafs\n",
        "\n",
        "depth = int(math.log2(training_width/leaf_width))\n",
        "print(depth)\n",
        "\"\"\"\n",
        "depth = []\n",
        "for w in leaf_width:\n",
        "    for ℓ in training_width:\n",
        "        d = math.log2(w / ℓ)\n",
        "        depth.append(d)\n",
        "\"\"\"\n",
        "entropy_effect = 0.0\n",
        "\n",
        "leaf_dropout = 0.0\n",
        "region_leak = 0.0\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "from vit_pytorch.vit import ViT\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# CIFAR-10 dataset with augmentations\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomApply([transforms.RandomAffine(degrees=45, translate=(0.1, 0.1), scale=(0.8, 1.2))], p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "\n",
        "# Model configuration\n",
        "model = myViT(\n",
        "    image_size=32,\n",
        "    patch_size=4,\n",
        "    num_classes=10,\n",
        "    dim=128,\n",
        "    depth=4,\n",
        "    heads=8,\n",
        "    mlp_dim=128,\n",
        "    dim_head=64,\n",
        "    dropout=0,\n",
        "    emb_dropout=0.1,\n",
        "    fff_model=True,\n",
        ").to(device)\n",
        "\n",
        "# Optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=4e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "milestones = [150, 300]\n",
        "gamma = 0.5\n",
        "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)\n",
        "\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 450\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs, _ = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "print(\"Training completed.\")\n",
        "\n",
        "\n",
        "# Evaluation on test set\n",
        "model.eval()\n",
        "all_preds, all_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs,_ = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# h=0 acc=64.74 100 epochs\n",
        "# h=5 acc=54.21 50 epochs\n",
        "# h=10 acc=58.35 50 epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw1gxLZNjBz7",
        "outputId": "c0987242-f59e-4496-91b5-135d33a7520d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training completed.\n",
            "Test Accuracy: 63.56%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# speedup\n",
        "# only here time has meaning\n",
        "\n",
        "activation = nn.ReLU()\n",
        "batch_size = 256\n",
        "\n",
        "leaf_width = 32         # [1, 2, 4, 8]\n",
        "training_width = 128     # [16, 32, 64, 128]    # number of all neurons in leafs\n",
        "\n",
        "depth = int(math.log2(training_width/leaf_width))\n",
        "print(depth)\n",
        "\"\"\"\n",
        "depth = []\n",
        "for w in leaf_width:\n",
        "    for ℓ in training_width:\n",
        "        d = math.log2(w / ℓ)\n",
        "        depth.append(d)\n",
        "\"\"\"\n",
        "entropy_effect = 0.0\n",
        "\n",
        "leaf_dropout = 0.0\n",
        "region_leak = 0.0\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "from vit_pytorch.vit import ViT\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# CIFAR-10 dataset with augmentations\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomApply([transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), scale=(0.8, 1.2))], p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "\n",
        "# Model configuration\n",
        "model = myViT(\n",
        "    image_size=32,\n",
        "    patch_size=4,\n",
        "    num_classes=10,\n",
        "    dim=128,\n",
        "    depth=4,\n",
        "    heads=8,\n",
        "    mlp_dim=128,\n",
        "    dim_head=64,\n",
        "    dropout=0,\n",
        "    emb_dropout=0.1,\n",
        "    fff_model=True,\n",
        ").to(device)\n",
        "\n",
        "# Optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=4e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=30, verbose=True)\n",
        "\n",
        "# Evaluation loop\n",
        "num_epochs = 100\n",
        "\n",
        "total_time = 0\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  model.eval()\n",
        "  all_preds, all_labels = [], []\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for images, labels in test_loader:\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "          outputs, time = model(images)\n",
        "          total_time += time\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "          all_preds.extend(preds.cpu().numpy())\n",
        "          all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate the total number of passes\n",
        "total_passes = len(test_loader.dataset)\n",
        "\n",
        "# Calculate and print the average inference time per pass\n",
        "average_time_per_batch = total_time / total_passes\n",
        "print(f\"Total Average Inference Time: {average_time_per_batch:.5f} milliseconds\")\n",
        "\n",
        "# Calculate overall accuracy\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "# h=0 acc=64.74 100 epochs\n",
        "# h=5 acc=54.21 50 epochs\n",
        "# h=10 acc=58.35 50 epochs"
      ],
      "metadata": {
        "id": "5vbuatHJjTM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a45f9a-0fe0-4b1b-a628-a94ebc145074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Total Average Inference Time: 0.00000 milliseconds\n",
            "Test Accuracy: 11.06%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total Average Inference Time: {average_time_per_batch*total_passes:.5f} milliseconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whAhxYtwlOEz",
        "outputId": "89c5698d-fab3-4104-c4d6-65869d37d9ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Average Inference Time: 444454.71875 milliseconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e8YZXNgElVma"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}